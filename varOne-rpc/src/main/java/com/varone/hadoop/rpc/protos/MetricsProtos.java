// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: metrics.proto

package com.varone.hadoop.rpc.protos;

public final class MetricsProtos {
  private MetricsProtos() {}
  public static void registerAllExtensions(
      com.google.protobuf.ExtensionRegistry registry) {
  }
  /**
   * Protobuf enum {@code MetricsTypeProto}
   */
  public enum MetricsTypeProto
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>FS = 0;</code>
     */
    FS(0, 0),
    /**
     * <code>JVM = 1;</code>
     */
    JVM(1, 1),
    /**
     * <code>GC = 2;</code>
     */
    GC(2, 2),
    /**
     * <code>THREAD_POOL = 3;</code>
     */
    THREAD_POOL(3, 3),
    /**
     * <code>EXEC_FS_LOCAL_LARGEREAD_OPS = 4;</code>
     */
    EXEC_FS_LOCAL_LARGEREAD_OPS(4, 4),
    /**
     * <code>EXEC_FS_LOCAL_READ_BYTES = 5;</code>
     */
    EXEC_FS_LOCAL_READ_BYTES(5, 5),
    /**
     * <code>EXEC_FS_LOCAL_READ_OPS = 6;</code>
     */
    EXEC_FS_LOCAL_READ_OPS(6, 6),
    /**
     * <code>EXEC_FS_LOCAL_WRITE_BYTES = 7;</code>
     */
    EXEC_FS_LOCAL_WRITE_BYTES(7, 7),
    /**
     * <code>EXEC_FS_LOCAL_WRITE_OPS = 8;</code>
     */
    EXEC_FS_LOCAL_WRITE_OPS(8, 8),
    /**
     * <code>EXEC_FS_HDFS_LARGEREAD_OPS = 9;</code>
     */
    EXEC_FS_HDFS_LARGEREAD_OPS(9, 9),
    /**
     * <code>EXEC_FS_HDFS_READ_BYTES = 10;</code>
     */
    EXEC_FS_HDFS_READ_BYTES(10, 10),
    /**
     * <code>EXEC_FS_HDFS_READ_OPS = 11;</code>
     */
    EXEC_FS_HDFS_READ_OPS(11, 11),
    /**
     * <code>EXEC_FS_HDFS_WRITE_BYTES = 12;</code>
     */
    EXEC_FS_HDFS_WRITE_BYTES(12, 12),
    /**
     * <code>EXEC_FS_HDFS_WRITE_OPS = 13;</code>
     */
    EXEC_FS_HDFS_WRITE_OPS(13, 13),
    /**
     * <code>EXEC_THREADPOOL_ACTIVETASK = 14;</code>
     */
    EXEC_THREADPOOL_ACTIVETASK(14, 14),
    /**
     * <code>EXEC_THREADPOOL_COMPLETETASK = 15;</code>
     */
    EXEC_THREADPOOL_COMPLETETASK(15, 15),
    /**
     * <code>EXEC_THREADPOOL_CURRPOOL_SIZE = 16;</code>
     */
    EXEC_THREADPOOL_CURRPOOL_SIZE(16, 16),
    /**
     * <code>EXEC_THREADPOOL_MAXPOOL_SIZE = 17;</code>
     */
    EXEC_THREADPOOL_MAXPOOL_SIZE(17, 17),
    /**
     * <code>JVM_HEAP_COMMITED = 18;</code>
     */
    JVM_HEAP_COMMITED(18, 18),
    /**
     * <code>JVM_HEAP_INIT = 19;</code>
     */
    JVM_HEAP_INIT(19, 19),
    /**
     * <code>JVM_HEAP_MAX = 20;</code>
     */
    JVM_HEAP_MAX(20, 20),
    /**
     * <code>JVM_HEAP_USAGE = 21;</code>
     */
    JVM_HEAP_USAGE(21, 21),
    /**
     * <code>JVM_HEAP_USED = 22;</code>
     */
    JVM_HEAP_USED(22, 22),
    /**
     * <code>JVM_NON_HEAP_COMMITED = 23;</code>
     */
    JVM_NON_HEAP_COMMITED(23, 23),
    /**
     * <code>JVM_NON_HEAP_INIT = 24;</code>
     */
    JVM_NON_HEAP_INIT(24, 24),
    /**
     * <code>JVM_NON_HEAP_MAX = 25;</code>
     */
    JVM_NON_HEAP_MAX(25, 25),
    /**
     * <code>JVM_NON_HEAP_USAGE = 26;</code>
     */
    JVM_NON_HEAP_USAGE(26, 26),
    /**
     * <code>JVM_NON_HEAP_USED = 27;</code>
     */
    JVM_NON_HEAP_USED(27, 27),
    /**
     * <code>JVM_POOLS_CODE_CACHE_USAGE = 28;</code>
     */
    JVM_POOLS_CODE_CACHE_USAGE(28, 28),
    /**
     * <code>JVM_POOLS_PS_EDEN_SPACE_USAGE = 29;</code>
     */
    JVM_POOLS_PS_EDEN_SPACE_USAGE(29, 29),
    /**
     * <code>JVM_POOLS_PS_OLD_GEN_USAGE = 30;</code>
     */
    JVM_POOLS_PS_OLD_GEN_USAGE(30, 30),
    /**
     * <code>JVM_POOLS_PS_PERM_GEN_USAGE = 31;</code>
     */
    JVM_POOLS_PS_PERM_GEN_USAGE(31, 31),
    /**
     * <code>JVM_POOLS_PS_SURVIVOR_SPACE_USAGE = 32;</code>
     */
    JVM_POOLS_PS_SURVIVOR_SPACE_USAGE(32, 32),
    /**
     * <code>JVM_PS_MARKSWEEP_COUNT = 33;</code>
     */
    JVM_PS_MARKSWEEP_COUNT(33, 33),
    /**
     * <code>JVM_PS_MARKSWEEP_TIME = 34;</code>
     */
    JVM_PS_MARKSWEEP_TIME(34, 34),
    /**
     * <code>JVM_PS_SCAVENGE_COUNT = 35;</code>
     */
    JVM_PS_SCAVENGE_COUNT(35, 35),
    /**
     * <code>JVM_PS_SCAVENGE_TIME = 36;</code>
     */
    JVM_PS_SCAVENGE_TIME(36, 36),
    ;

    /**
     * <code>FS = 0;</code>
     */
    public static final int FS_VALUE = 0;
    /**
     * <code>JVM = 1;</code>
     */
    public static final int JVM_VALUE = 1;
    /**
     * <code>GC = 2;</code>
     */
    public static final int GC_VALUE = 2;
    /**
     * <code>THREAD_POOL = 3;</code>
     */
    public static final int THREAD_POOL_VALUE = 3;
    /**
     * <code>EXEC_FS_LOCAL_LARGEREAD_OPS = 4;</code>
     */
    public static final int EXEC_FS_LOCAL_LARGEREAD_OPS_VALUE = 4;
    /**
     * <code>EXEC_FS_LOCAL_READ_BYTES = 5;</code>
     */
    public static final int EXEC_FS_LOCAL_READ_BYTES_VALUE = 5;
    /**
     * <code>EXEC_FS_LOCAL_READ_OPS = 6;</code>
     */
    public static final int EXEC_FS_LOCAL_READ_OPS_VALUE = 6;
    /**
     * <code>EXEC_FS_LOCAL_WRITE_BYTES = 7;</code>
     */
    public static final int EXEC_FS_LOCAL_WRITE_BYTES_VALUE = 7;
    /**
     * <code>EXEC_FS_LOCAL_WRITE_OPS = 8;</code>
     */
    public static final int EXEC_FS_LOCAL_WRITE_OPS_VALUE = 8;
    /**
     * <code>EXEC_FS_HDFS_LARGEREAD_OPS = 9;</code>
     */
    public static final int EXEC_FS_HDFS_LARGEREAD_OPS_VALUE = 9;
    /**
     * <code>EXEC_FS_HDFS_READ_BYTES = 10;</code>
     */
    public static final int EXEC_FS_HDFS_READ_BYTES_VALUE = 10;
    /**
     * <code>EXEC_FS_HDFS_READ_OPS = 11;</code>
     */
    public static final int EXEC_FS_HDFS_READ_OPS_VALUE = 11;
    /**
     * <code>EXEC_FS_HDFS_WRITE_BYTES = 12;</code>
     */
    public static final int EXEC_FS_HDFS_WRITE_BYTES_VALUE = 12;
    /**
     * <code>EXEC_FS_HDFS_WRITE_OPS = 13;</code>
     */
    public static final int EXEC_FS_HDFS_WRITE_OPS_VALUE = 13;
    /**
     * <code>EXEC_THREADPOOL_ACTIVETASK = 14;</code>
     */
    public static final int EXEC_THREADPOOL_ACTIVETASK_VALUE = 14;
    /**
     * <code>EXEC_THREADPOOL_COMPLETETASK = 15;</code>
     */
    public static final int EXEC_THREADPOOL_COMPLETETASK_VALUE = 15;
    /**
     * <code>EXEC_THREADPOOL_CURRPOOL_SIZE = 16;</code>
     */
    public static final int EXEC_THREADPOOL_CURRPOOL_SIZE_VALUE = 16;
    /**
     * <code>EXEC_THREADPOOL_MAXPOOL_SIZE = 17;</code>
     */
    public static final int EXEC_THREADPOOL_MAXPOOL_SIZE_VALUE = 17;
    /**
     * <code>JVM_HEAP_COMMITED = 18;</code>
     */
    public static final int JVM_HEAP_COMMITED_VALUE = 18;
    /**
     * <code>JVM_HEAP_INIT = 19;</code>
     */
    public static final int JVM_HEAP_INIT_VALUE = 19;
    /**
     * <code>JVM_HEAP_MAX = 20;</code>
     */
    public static final int JVM_HEAP_MAX_VALUE = 20;
    /**
     * <code>JVM_HEAP_USAGE = 21;</code>
     */
    public static final int JVM_HEAP_USAGE_VALUE = 21;
    /**
     * <code>JVM_HEAP_USED = 22;</code>
     */
    public static final int JVM_HEAP_USED_VALUE = 22;
    /**
     * <code>JVM_NON_HEAP_COMMITED = 23;</code>
     */
    public static final int JVM_NON_HEAP_COMMITED_VALUE = 23;
    /**
     * <code>JVM_NON_HEAP_INIT = 24;</code>
     */
    public static final int JVM_NON_HEAP_INIT_VALUE = 24;
    /**
     * <code>JVM_NON_HEAP_MAX = 25;</code>
     */
    public static final int JVM_NON_HEAP_MAX_VALUE = 25;
    /**
     * <code>JVM_NON_HEAP_USAGE = 26;</code>
     */
    public static final int JVM_NON_HEAP_USAGE_VALUE = 26;
    /**
     * <code>JVM_NON_HEAP_USED = 27;</code>
     */
    public static final int JVM_NON_HEAP_USED_VALUE = 27;
    /**
     * <code>JVM_POOLS_CODE_CACHE_USAGE = 28;</code>
     */
    public static final int JVM_POOLS_CODE_CACHE_USAGE_VALUE = 28;
    /**
     * <code>JVM_POOLS_PS_EDEN_SPACE_USAGE = 29;</code>
     */
    public static final int JVM_POOLS_PS_EDEN_SPACE_USAGE_VALUE = 29;
    /**
     * <code>JVM_POOLS_PS_OLD_GEN_USAGE = 30;</code>
     */
    public static final int JVM_POOLS_PS_OLD_GEN_USAGE_VALUE = 30;
    /**
     * <code>JVM_POOLS_PS_PERM_GEN_USAGE = 31;</code>
     */
    public static final int JVM_POOLS_PS_PERM_GEN_USAGE_VALUE = 31;
    /**
     * <code>JVM_POOLS_PS_SURVIVOR_SPACE_USAGE = 32;</code>
     */
    public static final int JVM_POOLS_PS_SURVIVOR_SPACE_USAGE_VALUE = 32;
    /**
     * <code>JVM_PS_MARKSWEEP_COUNT = 33;</code>
     */
    public static final int JVM_PS_MARKSWEEP_COUNT_VALUE = 33;
    /**
     * <code>JVM_PS_MARKSWEEP_TIME = 34;</code>
     */
    public static final int JVM_PS_MARKSWEEP_TIME_VALUE = 34;
    /**
     * <code>JVM_PS_SCAVENGE_COUNT = 35;</code>
     */
    public static final int JVM_PS_SCAVENGE_COUNT_VALUE = 35;
    /**
     * <code>JVM_PS_SCAVENGE_TIME = 36;</code>
     */
    public static final int JVM_PS_SCAVENGE_TIME_VALUE = 36;


    public final int getNumber() { return value; }

    public static MetricsTypeProto valueOf(int value) {
      switch (value) {
        case 0: return FS;
        case 1: return JVM;
        case 2: return GC;
        case 3: return THREAD_POOL;
        case 4: return EXEC_FS_LOCAL_LARGEREAD_OPS;
        case 5: return EXEC_FS_LOCAL_READ_BYTES;
        case 6: return EXEC_FS_LOCAL_READ_OPS;
        case 7: return EXEC_FS_LOCAL_WRITE_BYTES;
        case 8: return EXEC_FS_LOCAL_WRITE_OPS;
        case 9: return EXEC_FS_HDFS_LARGEREAD_OPS;
        case 10: return EXEC_FS_HDFS_READ_BYTES;
        case 11: return EXEC_FS_HDFS_READ_OPS;
        case 12: return EXEC_FS_HDFS_WRITE_BYTES;
        case 13: return EXEC_FS_HDFS_WRITE_OPS;
        case 14: return EXEC_THREADPOOL_ACTIVETASK;
        case 15: return EXEC_THREADPOOL_COMPLETETASK;
        case 16: return EXEC_THREADPOOL_CURRPOOL_SIZE;
        case 17: return EXEC_THREADPOOL_MAXPOOL_SIZE;
        case 18: return JVM_HEAP_COMMITED;
        case 19: return JVM_HEAP_INIT;
        case 20: return JVM_HEAP_MAX;
        case 21: return JVM_HEAP_USAGE;
        case 22: return JVM_HEAP_USED;
        case 23: return JVM_NON_HEAP_COMMITED;
        case 24: return JVM_NON_HEAP_INIT;
        case 25: return JVM_NON_HEAP_MAX;
        case 26: return JVM_NON_HEAP_USAGE;
        case 27: return JVM_NON_HEAP_USED;
        case 28: return JVM_POOLS_CODE_CACHE_USAGE;
        case 29: return JVM_POOLS_PS_EDEN_SPACE_USAGE;
        case 30: return JVM_POOLS_PS_OLD_GEN_USAGE;
        case 31: return JVM_POOLS_PS_PERM_GEN_USAGE;
        case 32: return JVM_POOLS_PS_SURVIVOR_SPACE_USAGE;
        case 33: return JVM_PS_MARKSWEEP_COUNT;
        case 34: return JVM_PS_MARKSWEEP_TIME;
        case 35: return JVM_PS_SCAVENGE_COUNT;
        case 36: return JVM_PS_SCAVENGE_TIME;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<MetricsTypeProto>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static com.google.protobuf.Internal.EnumLiteMap<MetricsTypeProto>
        internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<MetricsTypeProto>() {
            public MetricsTypeProto findValueByNumber(int number) {
              return MetricsTypeProto.valueOf(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(index);
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return com.varone.hadoop.rpc.protos.MetricsProtos.getDescriptor().getEnumTypes().get(0);
    }

    private static final MetricsTypeProto[] VALUES = values();

    public static MetricsTypeProto valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int index;
    private final int value;

    private MetricsTypeProto(int index, int value) {
      this.index = index;
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:MetricsTypeProto)
  }

  public interface MetricsRequestProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // required string applicationId = 1;
    /**
     * <code>required string applicationId = 1;</code>
     */
    boolean hasApplicationId();
    /**
     * <code>required string applicationId = 1;</code>
     */
    java.lang.String getApplicationId();
    /**
     * <code>required string applicationId = 1;</code>
     */
    com.google.protobuf.ByteString
        getApplicationIdBytes();

    // repeated .MetricsTypeProto metrics = 2;
    /**
     * <code>repeated .MetricsTypeProto metrics = 2;</code>
     */
    java.util.List<com.varone.hadoop.rpc.protos.MetricsProtos.MetricsTypeProto> getMetricsList();
    /**
     * <code>repeated .MetricsTypeProto metrics = 2;</code>
     */
    int getMetricsCount();
    /**
     * <code>repeated .MetricsTypeProto metrics = 2;</code>
     */
    com.varone.hadoop.rpc.protos.MetricsProtos.MetricsTypeProto getMetrics(int index);
  }
  /**
   * Protobuf type {@code MetricsRequestProto}
   */
  public static final class MetricsRequestProto extends
      com.google.protobuf.GeneratedMessage
      implements MetricsRequestProtoOrBuilder {
    // Use MetricsRequestProto.newBuilder() to construct.
    private MetricsRequestProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private MetricsRequestProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final MetricsRequestProto defaultInstance;
    public static MetricsRequestProto getDefaultInstance() {
      return defaultInstance;
    }

    public MetricsRequestProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private MetricsRequestProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              bitField0_ |= 0x00000001;
              applicationId_ = input.readBytes();
              break;
            }
            case 16: {
              int rawValue = input.readEnum();
              com.varone.hadoop.rpc.protos.MetricsProtos.MetricsTypeProto value = com.varone.hadoop.rpc.protos.MetricsProtos.MetricsTypeProto.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(2, rawValue);
              } else {
                if (!((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
                  metrics_ = new java.util.ArrayList<com.varone.hadoop.rpc.protos.MetricsProtos.MetricsTypeProto>();
                  mutable_bitField0_ |= 0x00000002;
                }
                metrics_.add(value);
              }
              break;
            }
            case 18: {
              int length = input.readRawVarint32();
              int oldLimit = input.pushLimit(length);
              while(input.getBytesUntilLimit() > 0) {
                int rawValue = input.readEnum();
                com.varone.hadoop.rpc.protos.MetricsProtos.MetricsTypeProto value = com.varone.hadoop.rpc.protos.MetricsProtos.MetricsTypeProto.valueOf(rawValue);
                if (value == null) {
                  unknownFields.mergeVarintField(2, rawValue);
                } else {
                  if (!((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
                    metrics_ = new java.util.ArrayList<com.varone.hadoop.rpc.protos.MetricsProtos.MetricsTypeProto>();
                    mutable_bitField0_ |= 0x00000002;
                  }
                  metrics_.add(value);
                }
              }
              input.popLimit(oldLimit);
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
          metrics_ = java.util.Collections.unmodifiableList(metrics_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return com.varone.hadoop.rpc.protos.MetricsProtos.internal_static_MetricsRequestProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return com.varone.hadoop.rpc.protos.MetricsProtos.internal_static_MetricsRequestProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              com.varone.hadoop.rpc.protos.MetricsProtos.MetricsRequestProto.class, com.varone.hadoop.rpc.protos.MetricsProtos.MetricsRequestProto.Builder.class);
    }

    public static com.google.protobuf.Parser<MetricsRequestProto> PARSER =
        new com.google.protobuf.AbstractParser<MetricsRequestProto>() {
      public MetricsRequestProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new MetricsRequestProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<MetricsRequestProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // required string applicationId = 1;
    public static final int APPLICATIONID_FIELD_NUMBER = 1;
    private java.lang.Object applicationId_;
    /**
     * <code>required string applicationId = 1;</code>
     */
    public boolean hasApplicationId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required string applicationId = 1;</code>
     */
    public java.lang.String getApplicationId() {
      java.lang.Object ref = applicationId_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          applicationId_ = s;
        }
        return s;
      }
    }
    /**
     * <code>required string applicationId = 1;</code>
     */
    public com.google.protobuf.ByteString
        getApplicationIdBytes() {
      java.lang.Object ref = applicationId_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        applicationId_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // repeated .MetricsTypeProto metrics = 2;
    public static final int METRICS_FIELD_NUMBER = 2;
    private java.util.List<com.varone.hadoop.rpc.protos.MetricsProtos.MetricsTypeProto> metrics_;
    /**
     * <code>repeated .MetricsTypeProto metrics = 2;</code>
     */
    public java.util.List<com.varone.hadoop.rpc.protos.MetricsProtos.MetricsTypeProto> getMetricsList() {
      return metrics_;
    }
    /**
     * <code>repeated .MetricsTypeProto metrics = 2;</code>
     */
    public int getMetricsCount() {
      return metrics_.size();
    }
    /**
     * <code>repeated .MetricsTypeProto metrics = 2;</code>
     */
    public com.varone.hadoop.rpc.protos.MetricsProtos.MetricsTypeProto getMetrics(int index) {
      return metrics_.get(index);
    }

    private void initFields() {
      applicationId_ = "";
      metrics_ = java.util.Collections.emptyList();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (!hasApplicationId()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBytes(1, getApplicationIdBytes());
      }
      for (int i = 0; i < metrics_.size(); i++) {
        output.writeEnum(2, metrics_.get(i).getNumber());
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, getApplicationIdBytes());
      }
      {
        int dataSize = 0;
        for (int i = 0; i < metrics_.size(); i++) {
          dataSize += com.google.protobuf.CodedOutputStream
            .computeEnumSizeNoTag(metrics_.get(i).getNumber());
        }
        size += dataSize;
        size += 1 * metrics_.size();
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof com.varone.hadoop.rpc.protos.MetricsProtos.MetricsRequestProto)) {
        return super.equals(obj);
      }
      com.varone.hadoop.rpc.protos.MetricsProtos.MetricsRequestProto other = (com.varone.hadoop.rpc.protos.MetricsProtos.MetricsRequestProto) obj;

      boolean result = true;
      result = result && (hasApplicationId() == other.hasApplicationId());
      if (hasApplicationId()) {
        result = result && getApplicationId()
            .equals(other.getApplicationId());
      }
      result = result && getMetricsList()
          .equals(other.getMetricsList());
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasApplicationId()) {
        hash = (37 * hash) + APPLICATIONID_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationId().hashCode();
      }
      if (getMetricsCount() > 0) {
        hash = (37 * hash) + METRICS_FIELD_NUMBER;
        hash = (53 * hash) + hashEnumList(getMetricsList());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static com.varone.hadoop.rpc.protos.MetricsProtos.MetricsRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static com.varone.hadoop.rpc.protos.MetricsProtos.MetricsRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static com.varone.hadoop.rpc.protos.MetricsProtos.MetricsRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static com.varone.hadoop.rpc.protos.MetricsProtos.MetricsRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static com.varone.hadoop.rpc.protos.MetricsProtos.MetricsRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static com.varone.hadoop.rpc.protos.MetricsProtos.MetricsRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static com.varone.hadoop.rpc.protos.MetricsProtos.MetricsRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static com.varone.hadoop.rpc.protos.MetricsProtos.MetricsRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static com.varone.hadoop.rpc.protos.MetricsProtos.MetricsRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static com.varone.hadoop.rpc.protos.MetricsProtos.MetricsRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(com.varone.hadoop.rpc.protos.MetricsProtos.MetricsRequestProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code MetricsRequestProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements com.varone.hadoop.rpc.protos.MetricsProtos.MetricsRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return com.varone.hadoop.rpc.protos.MetricsProtos.internal_static_MetricsRequestProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return com.varone.hadoop.rpc.protos.MetricsProtos.internal_static_MetricsRequestProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                com.varone.hadoop.rpc.protos.MetricsProtos.MetricsRequestProto.class, com.varone.hadoop.rpc.protos.MetricsProtos.MetricsRequestProto.Builder.class);
      }

      // Construct using com.haredb.sparkmonitor.hadoop.rpc.protos.MetricsProtos.MetricsRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        applicationId_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        metrics_ = java.util.Collections.emptyList();
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return com.varone.hadoop.rpc.protos.MetricsProtos.internal_static_MetricsRequestProto_descriptor;
      }

      public com.varone.hadoop.rpc.protos.MetricsProtos.MetricsRequestProto getDefaultInstanceForType() {
        return com.varone.hadoop.rpc.protos.MetricsProtos.MetricsRequestProto.getDefaultInstance();
      }

      public com.varone.hadoop.rpc.protos.MetricsProtos.MetricsRequestProto build() {
        com.varone.hadoop.rpc.protos.MetricsProtos.MetricsRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public com.varone.hadoop.rpc.protos.MetricsProtos.MetricsRequestProto buildPartial() {
        com.varone.hadoop.rpc.protos.MetricsProtos.MetricsRequestProto result = new com.varone.hadoop.rpc.protos.MetricsProtos.MetricsRequestProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.applicationId_ = applicationId_;
        if (((bitField0_ & 0x00000002) == 0x00000002)) {
          metrics_ = java.util.Collections.unmodifiableList(metrics_);
          bitField0_ = (bitField0_ & ~0x00000002);
        }
        result.metrics_ = metrics_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof com.varone.hadoop.rpc.protos.MetricsProtos.MetricsRequestProto) {
          return mergeFrom((com.varone.hadoop.rpc.protos.MetricsProtos.MetricsRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(com.varone.hadoop.rpc.protos.MetricsProtos.MetricsRequestProto other) {
        if (other == com.varone.hadoop.rpc.protos.MetricsProtos.MetricsRequestProto.getDefaultInstance()) return this;
        if (other.hasApplicationId()) {
          bitField0_ |= 0x00000001;
          applicationId_ = other.applicationId_;
          onChanged();
        }
        if (!other.metrics_.isEmpty()) {
          if (metrics_.isEmpty()) {
            metrics_ = other.metrics_;
            bitField0_ = (bitField0_ & ~0x00000002);
          } else {
            ensureMetricsIsMutable();
            metrics_.addAll(other.metrics_);
          }
          onChanged();
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (!hasApplicationId()) {
          
          return false;
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.varone.hadoop.rpc.protos.MetricsProtos.MetricsRequestProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (com.varone.hadoop.rpc.protos.MetricsProtos.MetricsRequestProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // required string applicationId = 1;
      private java.lang.Object applicationId_ = "";
      /**
       * <code>required string applicationId = 1;</code>
       */
      public boolean hasApplicationId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required string applicationId = 1;</code>
       */
      public java.lang.String getApplicationId() {
        java.lang.Object ref = applicationId_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          applicationId_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>required string applicationId = 1;</code>
       */
      public com.google.protobuf.ByteString
          getApplicationIdBytes() {
        java.lang.Object ref = applicationId_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          applicationId_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>required string applicationId = 1;</code>
       */
      public Builder setApplicationId(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        applicationId_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required string applicationId = 1;</code>
       */
      public Builder clearApplicationId() {
        bitField0_ = (bitField0_ & ~0x00000001);
        applicationId_ = getDefaultInstance().getApplicationId();
        onChanged();
        return this;
      }
      /**
       * <code>required string applicationId = 1;</code>
       */
      public Builder setApplicationIdBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        applicationId_ = value;
        onChanged();
        return this;
      }

      // repeated .MetricsTypeProto metrics = 2;
      private java.util.List<com.varone.hadoop.rpc.protos.MetricsProtos.MetricsTypeProto> metrics_ =
        java.util.Collections.emptyList();
      private void ensureMetricsIsMutable() {
        if (!((bitField0_ & 0x00000002) == 0x00000002)) {
          metrics_ = new java.util.ArrayList<com.varone.hadoop.rpc.protos.MetricsProtos.MetricsTypeProto>(metrics_);
          bitField0_ |= 0x00000002;
        }
      }
      /**
       * <code>repeated .MetricsTypeProto metrics = 2;</code>
       */
      public java.util.List<com.varone.hadoop.rpc.protos.MetricsProtos.MetricsTypeProto> getMetricsList() {
        return java.util.Collections.unmodifiableList(metrics_);
      }
      /**
       * <code>repeated .MetricsTypeProto metrics = 2;</code>
       */
      public int getMetricsCount() {
        return metrics_.size();
      }
      /**
       * <code>repeated .MetricsTypeProto metrics = 2;</code>
       */
      public com.varone.hadoop.rpc.protos.MetricsProtos.MetricsTypeProto getMetrics(int index) {
        return metrics_.get(index);
      }
      /**
       * <code>repeated .MetricsTypeProto metrics = 2;</code>
       */
      public Builder setMetrics(
          int index, com.varone.hadoop.rpc.protos.MetricsProtos.MetricsTypeProto value) {
        if (value == null) {
          throw new NullPointerException();
        }
        ensureMetricsIsMutable();
        metrics_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated .MetricsTypeProto metrics = 2;</code>
       */
      public Builder addMetrics(com.varone.hadoop.rpc.protos.MetricsProtos.MetricsTypeProto value) {
        if (value == null) {
          throw new NullPointerException();
        }
        ensureMetricsIsMutable();
        metrics_.add(value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated .MetricsTypeProto metrics = 2;</code>
       */
      public Builder addAllMetrics(
          java.lang.Iterable<? extends com.varone.hadoop.rpc.protos.MetricsProtos.MetricsTypeProto> values) {
        ensureMetricsIsMutable();
        super.addAll(values, metrics_);
        onChanged();
        return this;
      }
      /**
       * <code>repeated .MetricsTypeProto metrics = 2;</code>
       */
      public Builder clearMetrics() {
        metrics_ = java.util.Collections.emptyList();
        bitField0_ = (bitField0_ & ~0x00000002);
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:MetricsRequestProto)
    }

    static {
      defaultInstance = new MetricsRequestProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:MetricsRequestProto)
  }

  public interface MetricsResponseProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // repeated .MetricsResponseProto.MetricsMapProto result = 1;
    /**
     * <code>repeated .MetricsResponseProto.MetricsMapProto result = 1;</code>
     */
    java.util.List<com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto> 
        getResultList();
    /**
     * <code>repeated .MetricsResponseProto.MetricsMapProto result = 1;</code>
     */
    com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto getResult(int index);
    /**
     * <code>repeated .MetricsResponseProto.MetricsMapProto result = 1;</code>
     */
    int getResultCount();
    /**
     * <code>repeated .MetricsResponseProto.MetricsMapProto result = 1;</code>
     */
    java.util.List<? extends com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProtoOrBuilder> 
        getResultOrBuilderList();
    /**
     * <code>repeated .MetricsResponseProto.MetricsMapProto result = 1;</code>
     */
    com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProtoOrBuilder getResultOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code MetricsResponseProto}
   */
  public static final class MetricsResponseProto extends
      com.google.protobuf.GeneratedMessage
      implements MetricsResponseProtoOrBuilder {
    // Use MetricsResponseProto.newBuilder() to construct.
    private MetricsResponseProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private MetricsResponseProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final MetricsResponseProto defaultInstance;
    public static MetricsResponseProto getDefaultInstance() {
      return defaultInstance;
    }

    public MetricsResponseProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private MetricsResponseProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              if (!((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
                result_ = new java.util.ArrayList<com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto>();
                mutable_bitField0_ |= 0x00000001;
              }
              result_.add(input.readMessage(com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.PARSER, extensionRegistry));
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
          result_ = java.util.Collections.unmodifiableList(result_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return com.varone.hadoop.rpc.protos.MetricsProtos.internal_static_MetricsResponseProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return com.varone.hadoop.rpc.protos.MetricsProtos.internal_static_MetricsResponseProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.class, com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.Builder.class);
    }

    public static com.google.protobuf.Parser<MetricsResponseProto> PARSER =
        new com.google.protobuf.AbstractParser<MetricsResponseProto>() {
      public MetricsResponseProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new MetricsResponseProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<MetricsResponseProto> getParserForType() {
      return PARSER;
    }

    public interface MetricsMapProtoOrBuilder
        extends com.google.protobuf.MessageOrBuilder {

      // required string metricsName = 1;
      /**
       * <code>required string metricsName = 1;</code>
       */
      boolean hasMetricsName();
      /**
       * <code>required string metricsName = 1;</code>
       */
      java.lang.String getMetricsName();
      /**
       * <code>required string metricsName = 1;</code>
       */
      com.google.protobuf.ByteString
          getMetricsNameBytes();

      // repeated .MetricsResponseProto.MetricsMapProto.TupleProto metricsValues = 2;
      /**
       * <code>repeated .MetricsResponseProto.MetricsMapProto.TupleProto metricsValues = 2;</code>
       */
      java.util.List<com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProto> 
          getMetricsValuesList();
      /**
       * <code>repeated .MetricsResponseProto.MetricsMapProto.TupleProto metricsValues = 2;</code>
       */
      com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProto getMetricsValues(int index);
      /**
       * <code>repeated .MetricsResponseProto.MetricsMapProto.TupleProto metricsValues = 2;</code>
       */
      int getMetricsValuesCount();
      /**
       * <code>repeated .MetricsResponseProto.MetricsMapProto.TupleProto metricsValues = 2;</code>
       */
      java.util.List<? extends com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProtoOrBuilder> 
          getMetricsValuesOrBuilderList();
      /**
       * <code>repeated .MetricsResponseProto.MetricsMapProto.TupleProto metricsValues = 2;</code>
       */
      com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProtoOrBuilder getMetricsValuesOrBuilder(
          int index);
    }
    /**
     * Protobuf type {@code MetricsResponseProto.MetricsMapProto}
     */
    public static final class MetricsMapProto extends
        com.google.protobuf.GeneratedMessage
        implements MetricsMapProtoOrBuilder {
      // Use MetricsMapProto.newBuilder() to construct.
      private MetricsMapProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
        super(builder);
        this.unknownFields = builder.getUnknownFields();
      }
      private MetricsMapProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

      private static final MetricsMapProto defaultInstance;
      public static MetricsMapProto getDefaultInstance() {
        return defaultInstance;
      }

      public MetricsMapProto getDefaultInstanceForType() {
        return defaultInstance;
      }

      private final com.google.protobuf.UnknownFieldSet unknownFields;
      @java.lang.Override
      public final com.google.protobuf.UnknownFieldSet
          getUnknownFields() {
        return this.unknownFields;
      }
      private MetricsMapProto(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        initFields();
        int mutable_bitField0_ = 0;
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
            com.google.protobuf.UnknownFieldSet.newBuilder();
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              default: {
                if (!parseUnknownField(input, unknownFields,
                                       extensionRegistry, tag)) {
                  done = true;
                }
                break;
              }
              case 10: {
                bitField0_ |= 0x00000001;
                metricsName_ = input.readBytes();
                break;
              }
              case 18: {
                if (!((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
                  metricsValues_ = new java.util.ArrayList<com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProto>();
                  mutable_bitField0_ |= 0x00000002;
                }
                metricsValues_.add(input.readMessage(com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProto.PARSER, extensionRegistry));
                break;
              }
            }
          }
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(this);
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(
              e.getMessage()).setUnfinishedMessage(this);
        } finally {
          if (((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
            metricsValues_ = java.util.Collections.unmodifiableList(metricsValues_);
          }
          this.unknownFields = unknownFields.build();
          makeExtensionsImmutable();
        }
      }
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return com.varone.hadoop.rpc.protos.MetricsProtos.internal_static_MetricsResponseProto_MetricsMapProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return com.varone.hadoop.rpc.protos.MetricsProtos.internal_static_MetricsResponseProto_MetricsMapProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.class, com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.Builder.class);
      }

      public static com.google.protobuf.Parser<MetricsMapProto> PARSER =
          new com.google.protobuf.AbstractParser<MetricsMapProto>() {
        public MetricsMapProto parsePartialFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws com.google.protobuf.InvalidProtocolBufferException {
          return new MetricsMapProto(input, extensionRegistry);
        }
      };

      @java.lang.Override
      public com.google.protobuf.Parser<MetricsMapProto> getParserForType() {
        return PARSER;
      }

      public interface TupleProtoOrBuilder
          extends com.google.protobuf.MessageOrBuilder {

        // required int64 time = 1;
        /**
         * <code>required int64 time = 1;</code>
         */
        boolean hasTime();
        /**
         * <code>required int64 time = 1;</code>
         */
        long getTime();

        // optional string value = 2;
        /**
         * <code>optional string value = 2;</code>
         */
        boolean hasValue();
        /**
         * <code>optional string value = 2;</code>
         */
        java.lang.String getValue();
        /**
         * <code>optional string value = 2;</code>
         */
        com.google.protobuf.ByteString
            getValueBytes();
      }
      /**
       * Protobuf type {@code MetricsResponseProto.MetricsMapProto.TupleProto}
       */
      public static final class TupleProto extends
          com.google.protobuf.GeneratedMessage
          implements TupleProtoOrBuilder {
        // Use TupleProto.newBuilder() to construct.
        private TupleProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
          super(builder);
          this.unknownFields = builder.getUnknownFields();
        }
        private TupleProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

        private static final TupleProto defaultInstance;
        public static TupleProto getDefaultInstance() {
          return defaultInstance;
        }

        public TupleProto getDefaultInstanceForType() {
          return defaultInstance;
        }

        private final com.google.protobuf.UnknownFieldSet unknownFields;
        @java.lang.Override
        public final com.google.protobuf.UnknownFieldSet
            getUnknownFields() {
          return this.unknownFields;
        }
        private TupleProto(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws com.google.protobuf.InvalidProtocolBufferException {
          initFields();
          int mutable_bitField0_ = 0;
          com.google.protobuf.UnknownFieldSet.Builder unknownFields =
              com.google.protobuf.UnknownFieldSet.newBuilder();
          try {
            boolean done = false;
            while (!done) {
              int tag = input.readTag();
              switch (tag) {
                case 0:
                  done = true;
                  break;
                default: {
                  if (!parseUnknownField(input, unknownFields,
                                         extensionRegistry, tag)) {
                    done = true;
                  }
                  break;
                }
                case 8: {
                  bitField0_ |= 0x00000001;
                  time_ = input.readInt64();
                  break;
                }
                case 18: {
                  bitField0_ |= 0x00000002;
                  value_ = input.readBytes();
                  break;
                }
              }
            }
          } catch (com.google.protobuf.InvalidProtocolBufferException e) {
            throw e.setUnfinishedMessage(this);
          } catch (java.io.IOException e) {
            throw new com.google.protobuf.InvalidProtocolBufferException(
                e.getMessage()).setUnfinishedMessage(this);
          } finally {
            this.unknownFields = unknownFields.build();
            makeExtensionsImmutable();
          }
        }
        public static final com.google.protobuf.Descriptors.Descriptor
            getDescriptor() {
          return com.varone.hadoop.rpc.protos.MetricsProtos.internal_static_MetricsResponseProto_MetricsMapProto_TupleProto_descriptor;
        }

        protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
            internalGetFieldAccessorTable() {
          return com.varone.hadoop.rpc.protos.MetricsProtos.internal_static_MetricsResponseProto_MetricsMapProto_TupleProto_fieldAccessorTable
              .ensureFieldAccessorsInitialized(
                  com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProto.class, com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProto.Builder.class);
        }

        public static com.google.protobuf.Parser<TupleProto> PARSER =
            new com.google.protobuf.AbstractParser<TupleProto>() {
          public TupleProto parsePartialFrom(
              com.google.protobuf.CodedInputStream input,
              com.google.protobuf.ExtensionRegistryLite extensionRegistry)
              throws com.google.protobuf.InvalidProtocolBufferException {
            return new TupleProto(input, extensionRegistry);
          }
        };

        @java.lang.Override
        public com.google.protobuf.Parser<TupleProto> getParserForType() {
          return PARSER;
        }

        private int bitField0_;
        // required int64 time = 1;
        public static final int TIME_FIELD_NUMBER = 1;
        private long time_;
        /**
         * <code>required int64 time = 1;</code>
         */
        public boolean hasTime() {
          return ((bitField0_ & 0x00000001) == 0x00000001);
        }
        /**
         * <code>required int64 time = 1;</code>
         */
        public long getTime() {
          return time_;
        }

        // optional string value = 2;
        public static final int VALUE_FIELD_NUMBER = 2;
        private java.lang.Object value_;
        /**
         * <code>optional string value = 2;</code>
         */
        public boolean hasValue() {
          return ((bitField0_ & 0x00000002) == 0x00000002);
        }
        /**
         * <code>optional string value = 2;</code>
         */
        public java.lang.String getValue() {
          java.lang.Object ref = value_;
          if (ref instanceof java.lang.String) {
            return (java.lang.String) ref;
          } else {
            com.google.protobuf.ByteString bs = 
                (com.google.protobuf.ByteString) ref;
            java.lang.String s = bs.toStringUtf8();
            if (bs.isValidUtf8()) {
              value_ = s;
            }
            return s;
          }
        }
        /**
         * <code>optional string value = 2;</code>
         */
        public com.google.protobuf.ByteString
            getValueBytes() {
          java.lang.Object ref = value_;
          if (ref instanceof java.lang.String) {
            com.google.protobuf.ByteString b = 
                com.google.protobuf.ByteString.copyFromUtf8(
                    (java.lang.String) ref);
            value_ = b;
            return b;
          } else {
            return (com.google.protobuf.ByteString) ref;
          }
        }

        private void initFields() {
          time_ = 0L;
          value_ = "";
        }
        private byte memoizedIsInitialized = -1;
        public final boolean isInitialized() {
          byte isInitialized = memoizedIsInitialized;
          if (isInitialized != -1) return isInitialized == 1;

          if (!hasTime()) {
            memoizedIsInitialized = 0;
            return false;
          }
          memoizedIsInitialized = 1;
          return true;
        }

        public void writeTo(com.google.protobuf.CodedOutputStream output)
                            throws java.io.IOException {
          getSerializedSize();
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            output.writeInt64(1, time_);
          }
          if (((bitField0_ & 0x00000002) == 0x00000002)) {
            output.writeBytes(2, getValueBytes());
          }
          getUnknownFields().writeTo(output);
        }

        private int memoizedSerializedSize = -1;
        public int getSerializedSize() {
          int size = memoizedSerializedSize;
          if (size != -1) return size;

          size = 0;
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            size += com.google.protobuf.CodedOutputStream
              .computeInt64Size(1, time_);
          }
          if (((bitField0_ & 0x00000002) == 0x00000002)) {
            size += com.google.protobuf.CodedOutputStream
              .computeBytesSize(2, getValueBytes());
          }
          size += getUnknownFields().getSerializedSize();
          memoizedSerializedSize = size;
          return size;
        }

        private static final long serialVersionUID = 0L;
        @java.lang.Override
        protected java.lang.Object writeReplace()
            throws java.io.ObjectStreamException {
          return super.writeReplace();
        }

        @java.lang.Override
        public boolean equals(final java.lang.Object obj) {
          if (obj == this) {
           return true;
          }
          if (!(obj instanceof com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProto)) {
            return super.equals(obj);
          }
          com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProto other = (com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProto) obj;

          boolean result = true;
          result = result && (hasTime() == other.hasTime());
          if (hasTime()) {
            result = result && (getTime()
                == other.getTime());
          }
          result = result && (hasValue() == other.hasValue());
          if (hasValue()) {
            result = result && getValue()
                .equals(other.getValue());
          }
          result = result &&
              getUnknownFields().equals(other.getUnknownFields());
          return result;
        }

        private int memoizedHashCode = 0;
        @java.lang.Override
        public int hashCode() {
          if (memoizedHashCode != 0) {
            return memoizedHashCode;
          }
          int hash = 41;
          hash = (19 * hash) + getDescriptorForType().hashCode();
          if (hasTime()) {
            hash = (37 * hash) + TIME_FIELD_NUMBER;
            hash = (53 * hash) + hashLong(getTime());
          }
          if (hasValue()) {
            hash = (37 * hash) + VALUE_FIELD_NUMBER;
            hash = (53 * hash) + getValue().hashCode();
          }
          hash = (29 * hash) + getUnknownFields().hashCode();
          memoizedHashCode = hash;
          return hash;
        }

        public static com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProto parseFrom(
            com.google.protobuf.ByteString data)
            throws com.google.protobuf.InvalidProtocolBufferException {
          return PARSER.parseFrom(data);
        }
        public static com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProto parseFrom(
            com.google.protobuf.ByteString data,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws com.google.protobuf.InvalidProtocolBufferException {
          return PARSER.parseFrom(data, extensionRegistry);
        }
        public static com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProto parseFrom(byte[] data)
            throws com.google.protobuf.InvalidProtocolBufferException {
          return PARSER.parseFrom(data);
        }
        public static com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProto parseFrom(
            byte[] data,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws com.google.protobuf.InvalidProtocolBufferException {
          return PARSER.parseFrom(data, extensionRegistry);
        }
        public static com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProto parseFrom(java.io.InputStream input)
            throws java.io.IOException {
          return PARSER.parseFrom(input);
        }
        public static com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProto parseFrom(
            java.io.InputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws java.io.IOException {
          return PARSER.parseFrom(input, extensionRegistry);
        }
        public static com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProto parseDelimitedFrom(java.io.InputStream input)
            throws java.io.IOException {
          return PARSER.parseDelimitedFrom(input);
        }
        public static com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProto parseDelimitedFrom(
            java.io.InputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws java.io.IOException {
          return PARSER.parseDelimitedFrom(input, extensionRegistry);
        }
        public static com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProto parseFrom(
            com.google.protobuf.CodedInputStream input)
            throws java.io.IOException {
          return PARSER.parseFrom(input);
        }
        public static com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProto parseFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws java.io.IOException {
          return PARSER.parseFrom(input, extensionRegistry);
        }

        public static Builder newBuilder() { return Builder.create(); }
        public Builder newBuilderForType() { return newBuilder(); }
        public static Builder newBuilder(com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProto prototype) {
          return newBuilder().mergeFrom(prototype);
        }
        public Builder toBuilder() { return newBuilder(this); }

        @java.lang.Override
        protected Builder newBuilderForType(
            com.google.protobuf.GeneratedMessage.BuilderParent parent) {
          Builder builder = new Builder(parent);
          return builder;
        }
        /**
         * Protobuf type {@code MetricsResponseProto.MetricsMapProto.TupleProto}
         */
        public static final class Builder extends
            com.google.protobuf.GeneratedMessage.Builder<Builder>
           implements com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProtoOrBuilder {
          public static final com.google.protobuf.Descriptors.Descriptor
              getDescriptor() {
            return com.varone.hadoop.rpc.protos.MetricsProtos.internal_static_MetricsResponseProto_MetricsMapProto_TupleProto_descriptor;
          }

          protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
              internalGetFieldAccessorTable() {
            return com.varone.hadoop.rpc.protos.MetricsProtos.internal_static_MetricsResponseProto_MetricsMapProto_TupleProto_fieldAccessorTable
                .ensureFieldAccessorsInitialized(
                    com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProto.class, com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProto.Builder.class);
          }

          // Construct using com.haredb.sparkmonitor.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProto.newBuilder()
          private Builder() {
            maybeForceBuilderInitialization();
          }

          private Builder(
              com.google.protobuf.GeneratedMessage.BuilderParent parent) {
            super(parent);
            maybeForceBuilderInitialization();
          }
          private void maybeForceBuilderInitialization() {
            if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
            }
          }
          private static Builder create() {
            return new Builder();
          }

          public Builder clear() {
            super.clear();
            time_ = 0L;
            bitField0_ = (bitField0_ & ~0x00000001);
            value_ = "";
            bitField0_ = (bitField0_ & ~0x00000002);
            return this;
          }

          public Builder clone() {
            return create().mergeFrom(buildPartial());
          }

          public com.google.protobuf.Descriptors.Descriptor
              getDescriptorForType() {
            return com.varone.hadoop.rpc.protos.MetricsProtos.internal_static_MetricsResponseProto_MetricsMapProto_TupleProto_descriptor;
          }

          public com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProto getDefaultInstanceForType() {
            return com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProto.getDefaultInstance();
          }

          public com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProto build() {
            com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProto result = buildPartial();
            if (!result.isInitialized()) {
              throw newUninitializedMessageException(result);
            }
            return result;
          }

          public com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProto buildPartial() {
            com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProto result = new com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProto(this);
            int from_bitField0_ = bitField0_;
            int to_bitField0_ = 0;
            if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
              to_bitField0_ |= 0x00000001;
            }
            result.time_ = time_;
            if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
              to_bitField0_ |= 0x00000002;
            }
            result.value_ = value_;
            result.bitField0_ = to_bitField0_;
            onBuilt();
            return result;
          }

          public Builder mergeFrom(com.google.protobuf.Message other) {
            if (other instanceof com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProto) {
              return mergeFrom((com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProto)other);
            } else {
              super.mergeFrom(other);
              return this;
            }
          }

          public Builder mergeFrom(com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProto other) {
            if (other == com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProto.getDefaultInstance()) return this;
            if (other.hasTime()) {
              setTime(other.getTime());
            }
            if (other.hasValue()) {
              bitField0_ |= 0x00000002;
              value_ = other.value_;
              onChanged();
            }
            this.mergeUnknownFields(other.getUnknownFields());
            return this;
          }

          public final boolean isInitialized() {
            if (!hasTime()) {
              
              return false;
            }
            return true;
          }

          public Builder mergeFrom(
              com.google.protobuf.CodedInputStream input,
              com.google.protobuf.ExtensionRegistryLite extensionRegistry)
              throws java.io.IOException {
            com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProto parsedMessage = null;
            try {
              parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
            } catch (com.google.protobuf.InvalidProtocolBufferException e) {
              parsedMessage = (com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProto) e.getUnfinishedMessage();
              throw e;
            } finally {
              if (parsedMessage != null) {
                mergeFrom(parsedMessage);
              }
            }
            return this;
          }
          private int bitField0_;

          // required int64 time = 1;
          private long time_ ;
          /**
           * <code>required int64 time = 1;</code>
           */
          public boolean hasTime() {
            return ((bitField0_ & 0x00000001) == 0x00000001);
          }
          /**
           * <code>required int64 time = 1;</code>
           */
          public long getTime() {
            return time_;
          }
          /**
           * <code>required int64 time = 1;</code>
           */
          public Builder setTime(long value) {
            bitField0_ |= 0x00000001;
            time_ = value;
            onChanged();
            return this;
          }
          /**
           * <code>required int64 time = 1;</code>
           */
          public Builder clearTime() {
            bitField0_ = (bitField0_ & ~0x00000001);
            time_ = 0L;
            onChanged();
            return this;
          }

          // optional string value = 2;
          private java.lang.Object value_ = "";
          /**
           * <code>optional string value = 2;</code>
           */
          public boolean hasValue() {
            return ((bitField0_ & 0x00000002) == 0x00000002);
          }
          /**
           * <code>optional string value = 2;</code>
           */
          public java.lang.String getValue() {
            java.lang.Object ref = value_;
            if (!(ref instanceof java.lang.String)) {
              java.lang.String s = ((com.google.protobuf.ByteString) ref)
                  .toStringUtf8();
              value_ = s;
              return s;
            } else {
              return (java.lang.String) ref;
            }
          }
          /**
           * <code>optional string value = 2;</code>
           */
          public com.google.protobuf.ByteString
              getValueBytes() {
            java.lang.Object ref = value_;
            if (ref instanceof String) {
              com.google.protobuf.ByteString b = 
                  com.google.protobuf.ByteString.copyFromUtf8(
                      (java.lang.String) ref);
              value_ = b;
              return b;
            } else {
              return (com.google.protobuf.ByteString) ref;
            }
          }
          /**
           * <code>optional string value = 2;</code>
           */
          public Builder setValue(
              java.lang.String value) {
            if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
            value_ = value;
            onChanged();
            return this;
          }
          /**
           * <code>optional string value = 2;</code>
           */
          public Builder clearValue() {
            bitField0_ = (bitField0_ & ~0x00000002);
            value_ = getDefaultInstance().getValue();
            onChanged();
            return this;
          }
          /**
           * <code>optional string value = 2;</code>
           */
          public Builder setValueBytes(
              com.google.protobuf.ByteString value) {
            if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
            value_ = value;
            onChanged();
            return this;
          }

          // @@protoc_insertion_point(builder_scope:MetricsResponseProto.MetricsMapProto.TupleProto)
        }

        static {
          defaultInstance = new TupleProto(true);
          defaultInstance.initFields();
        }

        // @@protoc_insertion_point(class_scope:MetricsResponseProto.MetricsMapProto.TupleProto)
      }

      private int bitField0_;
      // required string metricsName = 1;
      public static final int METRICSNAME_FIELD_NUMBER = 1;
      private java.lang.Object metricsName_;
      /**
       * <code>required string metricsName = 1;</code>
       */
      public boolean hasMetricsName() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required string metricsName = 1;</code>
       */
      public java.lang.String getMetricsName() {
        java.lang.Object ref = metricsName_;
        if (ref instanceof java.lang.String) {
          return (java.lang.String) ref;
        } else {
          com.google.protobuf.ByteString bs = 
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            metricsName_ = s;
          }
          return s;
        }
      }
      /**
       * <code>required string metricsName = 1;</code>
       */
      public com.google.protobuf.ByteString
          getMetricsNameBytes() {
        java.lang.Object ref = metricsName_;
        if (ref instanceof java.lang.String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          metricsName_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }

      // repeated .MetricsResponseProto.MetricsMapProto.TupleProto metricsValues = 2;
      public static final int METRICSVALUES_FIELD_NUMBER = 2;
      private java.util.List<com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProto> metricsValues_;
      /**
       * <code>repeated .MetricsResponseProto.MetricsMapProto.TupleProto metricsValues = 2;</code>
       */
      public java.util.List<com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProto> getMetricsValuesList() {
        return metricsValues_;
      }
      /**
       * <code>repeated .MetricsResponseProto.MetricsMapProto.TupleProto metricsValues = 2;</code>
       */
      public java.util.List<? extends com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProtoOrBuilder> 
          getMetricsValuesOrBuilderList() {
        return metricsValues_;
      }
      /**
       * <code>repeated .MetricsResponseProto.MetricsMapProto.TupleProto metricsValues = 2;</code>
       */
      public int getMetricsValuesCount() {
        return metricsValues_.size();
      }
      /**
       * <code>repeated .MetricsResponseProto.MetricsMapProto.TupleProto metricsValues = 2;</code>
       */
      public com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProto getMetricsValues(int index) {
        return metricsValues_.get(index);
      }
      /**
       * <code>repeated .MetricsResponseProto.MetricsMapProto.TupleProto metricsValues = 2;</code>
       */
      public com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProtoOrBuilder getMetricsValuesOrBuilder(
          int index) {
        return metricsValues_.get(index);
      }

      private void initFields() {
        metricsName_ = "";
        metricsValues_ = java.util.Collections.emptyList();
      }
      private byte memoizedIsInitialized = -1;
      public final boolean isInitialized() {
        byte isInitialized = memoizedIsInitialized;
        if (isInitialized != -1) return isInitialized == 1;

        if (!hasMetricsName()) {
          memoizedIsInitialized = 0;
          return false;
        }
        for (int i = 0; i < getMetricsValuesCount(); i++) {
          if (!getMetricsValues(i).isInitialized()) {
            memoizedIsInitialized = 0;
            return false;
          }
        }
        memoizedIsInitialized = 1;
        return true;
      }

      public void writeTo(com.google.protobuf.CodedOutputStream output)
                          throws java.io.IOException {
        getSerializedSize();
        if (((bitField0_ & 0x00000001) == 0x00000001)) {
          output.writeBytes(1, getMetricsNameBytes());
        }
        for (int i = 0; i < metricsValues_.size(); i++) {
          output.writeMessage(2, metricsValues_.get(i));
        }
        getUnknownFields().writeTo(output);
      }

      private int memoizedSerializedSize = -1;
      public int getSerializedSize() {
        int size = memoizedSerializedSize;
        if (size != -1) return size;

        size = 0;
        if (((bitField0_ & 0x00000001) == 0x00000001)) {
          size += com.google.protobuf.CodedOutputStream
            .computeBytesSize(1, getMetricsNameBytes());
        }
        for (int i = 0; i < metricsValues_.size(); i++) {
          size += com.google.protobuf.CodedOutputStream
            .computeMessageSize(2, metricsValues_.get(i));
        }
        size += getUnknownFields().getSerializedSize();
        memoizedSerializedSize = size;
        return size;
      }

      private static final long serialVersionUID = 0L;
      @java.lang.Override
      protected java.lang.Object writeReplace()
          throws java.io.ObjectStreamException {
        return super.writeReplace();
      }

      @java.lang.Override
      public boolean equals(final java.lang.Object obj) {
        if (obj == this) {
         return true;
        }
        if (!(obj instanceof com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto)) {
          return super.equals(obj);
        }
        com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto other = (com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto) obj;

        boolean result = true;
        result = result && (hasMetricsName() == other.hasMetricsName());
        if (hasMetricsName()) {
          result = result && getMetricsName()
              .equals(other.getMetricsName());
        }
        result = result && getMetricsValuesList()
            .equals(other.getMetricsValuesList());
        result = result &&
            getUnknownFields().equals(other.getUnknownFields());
        return result;
      }

      private int memoizedHashCode = 0;
      @java.lang.Override
      public int hashCode() {
        if (memoizedHashCode != 0) {
          return memoizedHashCode;
        }
        int hash = 41;
        hash = (19 * hash) + getDescriptorForType().hashCode();
        if (hasMetricsName()) {
          hash = (37 * hash) + METRICSNAME_FIELD_NUMBER;
          hash = (53 * hash) + getMetricsName().hashCode();
        }
        if (getMetricsValuesCount() > 0) {
          hash = (37 * hash) + METRICSVALUES_FIELD_NUMBER;
          hash = (53 * hash) + getMetricsValuesList().hashCode();
        }
        hash = (29 * hash) + getUnknownFields().hashCode();
        memoizedHashCode = hash;
        return hash;
      }

      public static com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto parseFrom(
          com.google.protobuf.ByteString data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto parseFrom(
          com.google.protobuf.ByteString data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto parseFrom(byte[] data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto parseFrom(
          byte[] data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto parseFrom(java.io.InputStream input)
          throws java.io.IOException {
        return PARSER.parseFrom(input);
      }
      public static com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto parseFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return PARSER.parseFrom(input, extensionRegistry);
      }
      public static com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto parseDelimitedFrom(java.io.InputStream input)
          throws java.io.IOException {
        return PARSER.parseDelimitedFrom(input);
      }
      public static com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto parseDelimitedFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return PARSER.parseDelimitedFrom(input, extensionRegistry);
      }
      public static com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto parseFrom(
          com.google.protobuf.CodedInputStream input)
          throws java.io.IOException {
        return PARSER.parseFrom(input);
      }
      public static com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto parseFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return PARSER.parseFrom(input, extensionRegistry);
      }

      public static Builder newBuilder() { return Builder.create(); }
      public Builder newBuilderForType() { return newBuilder(); }
      public static Builder newBuilder(com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto prototype) {
        return newBuilder().mergeFrom(prototype);
      }
      public Builder toBuilder() { return newBuilder(this); }

      @java.lang.Override
      protected Builder newBuilderForType(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        Builder builder = new Builder(parent);
        return builder;
      }
      /**
       * Protobuf type {@code MetricsResponseProto.MetricsMapProto}
       */
      public static final class Builder extends
          com.google.protobuf.GeneratedMessage.Builder<Builder>
         implements com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProtoOrBuilder {
        public static final com.google.protobuf.Descriptors.Descriptor
            getDescriptor() {
          return com.varone.hadoop.rpc.protos.MetricsProtos.internal_static_MetricsResponseProto_MetricsMapProto_descriptor;
        }

        protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
            internalGetFieldAccessorTable() {
          return com.varone.hadoop.rpc.protos.MetricsProtos.internal_static_MetricsResponseProto_MetricsMapProto_fieldAccessorTable
              .ensureFieldAccessorsInitialized(
                  com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.class, com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.Builder.class);
        }

        // Construct using com.haredb.sparkmonitor.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.newBuilder()
        private Builder() {
          maybeForceBuilderInitialization();
        }

        private Builder(
            com.google.protobuf.GeneratedMessage.BuilderParent parent) {
          super(parent);
          maybeForceBuilderInitialization();
        }
        private void maybeForceBuilderInitialization() {
          if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
            getMetricsValuesFieldBuilder();
          }
        }
        private static Builder create() {
          return new Builder();
        }

        public Builder clear() {
          super.clear();
          metricsName_ = "";
          bitField0_ = (bitField0_ & ~0x00000001);
          if (metricsValuesBuilder_ == null) {
            metricsValues_ = java.util.Collections.emptyList();
            bitField0_ = (bitField0_ & ~0x00000002);
          } else {
            metricsValuesBuilder_.clear();
          }
          return this;
        }

        public Builder clone() {
          return create().mergeFrom(buildPartial());
        }

        public com.google.protobuf.Descriptors.Descriptor
            getDescriptorForType() {
          return com.varone.hadoop.rpc.protos.MetricsProtos.internal_static_MetricsResponseProto_MetricsMapProto_descriptor;
        }

        public com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto getDefaultInstanceForType() {
          return com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.getDefaultInstance();
        }

        public com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto build() {
          com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto result = buildPartial();
          if (!result.isInitialized()) {
            throw newUninitializedMessageException(result);
          }
          return result;
        }

        public com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto buildPartial() {
          com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto result = new com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto(this);
          int from_bitField0_ = bitField0_;
          int to_bitField0_ = 0;
          if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
            to_bitField0_ |= 0x00000001;
          }
          result.metricsName_ = metricsName_;
          if (metricsValuesBuilder_ == null) {
            if (((bitField0_ & 0x00000002) == 0x00000002)) {
              metricsValues_ = java.util.Collections.unmodifiableList(metricsValues_);
              bitField0_ = (bitField0_ & ~0x00000002);
            }
            result.metricsValues_ = metricsValues_;
          } else {
            result.metricsValues_ = metricsValuesBuilder_.build();
          }
          result.bitField0_ = to_bitField0_;
          onBuilt();
          return result;
        }

        public Builder mergeFrom(com.google.protobuf.Message other) {
          if (other instanceof com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto) {
            return mergeFrom((com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto)other);
          } else {
            super.mergeFrom(other);
            return this;
          }
        }

        public Builder mergeFrom(com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto other) {
          if (other == com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.getDefaultInstance()) return this;
          if (other.hasMetricsName()) {
            bitField0_ |= 0x00000001;
            metricsName_ = other.metricsName_;
            onChanged();
          }
          if (metricsValuesBuilder_ == null) {
            if (!other.metricsValues_.isEmpty()) {
              if (metricsValues_.isEmpty()) {
                metricsValues_ = other.metricsValues_;
                bitField0_ = (bitField0_ & ~0x00000002);
              } else {
                ensureMetricsValuesIsMutable();
                metricsValues_.addAll(other.metricsValues_);
              }
              onChanged();
            }
          } else {
            if (!other.metricsValues_.isEmpty()) {
              if (metricsValuesBuilder_.isEmpty()) {
                metricsValuesBuilder_.dispose();
                metricsValuesBuilder_ = null;
                metricsValues_ = other.metricsValues_;
                bitField0_ = (bitField0_ & ~0x00000002);
                metricsValuesBuilder_ = 
                  com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                     getMetricsValuesFieldBuilder() : null;
              } else {
                metricsValuesBuilder_.addAllMessages(other.metricsValues_);
              }
            }
          }
          this.mergeUnknownFields(other.getUnknownFields());
          return this;
        }

        public final boolean isInitialized() {
          if (!hasMetricsName()) {
            
            return false;
          }
          for (int i = 0; i < getMetricsValuesCount(); i++) {
            if (!getMetricsValues(i).isInitialized()) {
              
              return false;
            }
          }
          return true;
        }

        public Builder mergeFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws java.io.IOException {
          com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto parsedMessage = null;
          try {
            parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
          } catch (com.google.protobuf.InvalidProtocolBufferException e) {
            parsedMessage = (com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto) e.getUnfinishedMessage();
            throw e;
          } finally {
            if (parsedMessage != null) {
              mergeFrom(parsedMessage);
            }
          }
          return this;
        }
        private int bitField0_;

        // required string metricsName = 1;
        private java.lang.Object metricsName_ = "";
        /**
         * <code>required string metricsName = 1;</code>
         */
        public boolean hasMetricsName() {
          return ((bitField0_ & 0x00000001) == 0x00000001);
        }
        /**
         * <code>required string metricsName = 1;</code>
         */
        public java.lang.String getMetricsName() {
          java.lang.Object ref = metricsName_;
          if (!(ref instanceof java.lang.String)) {
            java.lang.String s = ((com.google.protobuf.ByteString) ref)
                .toStringUtf8();
            metricsName_ = s;
            return s;
          } else {
            return (java.lang.String) ref;
          }
        }
        /**
         * <code>required string metricsName = 1;</code>
         */
        public com.google.protobuf.ByteString
            getMetricsNameBytes() {
          java.lang.Object ref = metricsName_;
          if (ref instanceof String) {
            com.google.protobuf.ByteString b = 
                com.google.protobuf.ByteString.copyFromUtf8(
                    (java.lang.String) ref);
            metricsName_ = b;
            return b;
          } else {
            return (com.google.protobuf.ByteString) ref;
          }
        }
        /**
         * <code>required string metricsName = 1;</code>
         */
        public Builder setMetricsName(
            java.lang.String value) {
          if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
          metricsName_ = value;
          onChanged();
          return this;
        }
        /**
         * <code>required string metricsName = 1;</code>
         */
        public Builder clearMetricsName() {
          bitField0_ = (bitField0_ & ~0x00000001);
          metricsName_ = getDefaultInstance().getMetricsName();
          onChanged();
          return this;
        }
        /**
         * <code>required string metricsName = 1;</code>
         */
        public Builder setMetricsNameBytes(
            com.google.protobuf.ByteString value) {
          if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
          metricsName_ = value;
          onChanged();
          return this;
        }

        // repeated .MetricsResponseProto.MetricsMapProto.TupleProto metricsValues = 2;
        private java.util.List<com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProto> metricsValues_ =
          java.util.Collections.emptyList();
        private void ensureMetricsValuesIsMutable() {
          if (!((bitField0_ & 0x00000002) == 0x00000002)) {
            metricsValues_ = new java.util.ArrayList<com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProto>(metricsValues_);
            bitField0_ |= 0x00000002;
           }
        }

        private com.google.protobuf.RepeatedFieldBuilder<
            com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProto, com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProto.Builder, com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProtoOrBuilder> metricsValuesBuilder_;

        /**
         * <code>repeated .MetricsResponseProto.MetricsMapProto.TupleProto metricsValues = 2;</code>
         */
        public java.util.List<com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProto> getMetricsValuesList() {
          if (metricsValuesBuilder_ == null) {
            return java.util.Collections.unmodifiableList(metricsValues_);
          } else {
            return metricsValuesBuilder_.getMessageList();
          }
        }
        /**
         * <code>repeated .MetricsResponseProto.MetricsMapProto.TupleProto metricsValues = 2;</code>
         */
        public int getMetricsValuesCount() {
          if (metricsValuesBuilder_ == null) {
            return metricsValues_.size();
          } else {
            return metricsValuesBuilder_.getCount();
          }
        }
        /**
         * <code>repeated .MetricsResponseProto.MetricsMapProto.TupleProto metricsValues = 2;</code>
         */
        public com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProto getMetricsValues(int index) {
          if (metricsValuesBuilder_ == null) {
            return metricsValues_.get(index);
          } else {
            return metricsValuesBuilder_.getMessage(index);
          }
        }
        /**
         * <code>repeated .MetricsResponseProto.MetricsMapProto.TupleProto metricsValues = 2;</code>
         */
        public Builder setMetricsValues(
            int index, com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProto value) {
          if (metricsValuesBuilder_ == null) {
            if (value == null) {
              throw new NullPointerException();
            }
            ensureMetricsValuesIsMutable();
            metricsValues_.set(index, value);
            onChanged();
          } else {
            metricsValuesBuilder_.setMessage(index, value);
          }
          return this;
        }
        /**
         * <code>repeated .MetricsResponseProto.MetricsMapProto.TupleProto metricsValues = 2;</code>
         */
        public Builder setMetricsValues(
            int index, com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProto.Builder builderForValue) {
          if (metricsValuesBuilder_ == null) {
            ensureMetricsValuesIsMutable();
            metricsValues_.set(index, builderForValue.build());
            onChanged();
          } else {
            metricsValuesBuilder_.setMessage(index, builderForValue.build());
          }
          return this;
        }
        /**
         * <code>repeated .MetricsResponseProto.MetricsMapProto.TupleProto metricsValues = 2;</code>
         */
        public Builder addMetricsValues(com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProto value) {
          if (metricsValuesBuilder_ == null) {
            if (value == null) {
              throw new NullPointerException();
            }
            ensureMetricsValuesIsMutable();
            metricsValues_.add(value);
            onChanged();
          } else {
            metricsValuesBuilder_.addMessage(value);
          }
          return this;
        }
        /**
         * <code>repeated .MetricsResponseProto.MetricsMapProto.TupleProto metricsValues = 2;</code>
         */
        public Builder addMetricsValues(
            int index, com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProto value) {
          if (metricsValuesBuilder_ == null) {
            if (value == null) {
              throw new NullPointerException();
            }
            ensureMetricsValuesIsMutable();
            metricsValues_.add(index, value);
            onChanged();
          } else {
            metricsValuesBuilder_.addMessage(index, value);
          }
          return this;
        }
        /**
         * <code>repeated .MetricsResponseProto.MetricsMapProto.TupleProto metricsValues = 2;</code>
         */
        public Builder addMetricsValues(
            com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProto.Builder builderForValue) {
          if (metricsValuesBuilder_ == null) {
            ensureMetricsValuesIsMutable();
            metricsValues_.add(builderForValue.build());
            onChanged();
          } else {
            metricsValuesBuilder_.addMessage(builderForValue.build());
          }
          return this;
        }
        /**
         * <code>repeated .MetricsResponseProto.MetricsMapProto.TupleProto metricsValues = 2;</code>
         */
        public Builder addMetricsValues(
            int index, com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProto.Builder builderForValue) {
          if (metricsValuesBuilder_ == null) {
            ensureMetricsValuesIsMutable();
            metricsValues_.add(index, builderForValue.build());
            onChanged();
          } else {
            metricsValuesBuilder_.addMessage(index, builderForValue.build());
          }
          return this;
        }
        /**
         * <code>repeated .MetricsResponseProto.MetricsMapProto.TupleProto metricsValues = 2;</code>
         */
        public Builder addAllMetricsValues(
            java.lang.Iterable<? extends com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProto> values) {
          if (metricsValuesBuilder_ == null) {
            ensureMetricsValuesIsMutable();
            super.addAll(values, metricsValues_);
            onChanged();
          } else {
            metricsValuesBuilder_.addAllMessages(values);
          }
          return this;
        }
        /**
         * <code>repeated .MetricsResponseProto.MetricsMapProto.TupleProto metricsValues = 2;</code>
         */
        public Builder clearMetricsValues() {
          if (metricsValuesBuilder_ == null) {
            metricsValues_ = java.util.Collections.emptyList();
            bitField0_ = (bitField0_ & ~0x00000002);
            onChanged();
          } else {
            metricsValuesBuilder_.clear();
          }
          return this;
        }
        /**
         * <code>repeated .MetricsResponseProto.MetricsMapProto.TupleProto metricsValues = 2;</code>
         */
        public Builder removeMetricsValues(int index) {
          if (metricsValuesBuilder_ == null) {
            ensureMetricsValuesIsMutable();
            metricsValues_.remove(index);
            onChanged();
          } else {
            metricsValuesBuilder_.remove(index);
          }
          return this;
        }
        /**
         * <code>repeated .MetricsResponseProto.MetricsMapProto.TupleProto metricsValues = 2;</code>
         */
        public com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProto.Builder getMetricsValuesBuilder(
            int index) {
          return getMetricsValuesFieldBuilder().getBuilder(index);
        }
        /**
         * <code>repeated .MetricsResponseProto.MetricsMapProto.TupleProto metricsValues = 2;</code>
         */
        public com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProtoOrBuilder getMetricsValuesOrBuilder(
            int index) {
          if (metricsValuesBuilder_ == null) {
            return metricsValues_.get(index);  } else {
            return metricsValuesBuilder_.getMessageOrBuilder(index);
          }
        }
        /**
         * <code>repeated .MetricsResponseProto.MetricsMapProto.TupleProto metricsValues = 2;</code>
         */
        public java.util.List<? extends com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProtoOrBuilder> 
             getMetricsValuesOrBuilderList() {
          if (metricsValuesBuilder_ != null) {
            return metricsValuesBuilder_.getMessageOrBuilderList();
          } else {
            return java.util.Collections.unmodifiableList(metricsValues_);
          }
        }
        /**
         * <code>repeated .MetricsResponseProto.MetricsMapProto.TupleProto metricsValues = 2;</code>
         */
        public com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProto.Builder addMetricsValuesBuilder() {
          return getMetricsValuesFieldBuilder().addBuilder(
              com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProto.getDefaultInstance());
        }
        /**
         * <code>repeated .MetricsResponseProto.MetricsMapProto.TupleProto metricsValues = 2;</code>
         */
        public com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProto.Builder addMetricsValuesBuilder(
            int index) {
          return getMetricsValuesFieldBuilder().addBuilder(
              index, com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProto.getDefaultInstance());
        }
        /**
         * <code>repeated .MetricsResponseProto.MetricsMapProto.TupleProto metricsValues = 2;</code>
         */
        public java.util.List<com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProto.Builder> 
             getMetricsValuesBuilderList() {
          return getMetricsValuesFieldBuilder().getBuilderList();
        }
        private com.google.protobuf.RepeatedFieldBuilder<
            com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProto, com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProto.Builder, com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProtoOrBuilder> 
            getMetricsValuesFieldBuilder() {
          if (metricsValuesBuilder_ == null) {
            metricsValuesBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
                com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProto, com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProto.Builder, com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.TupleProtoOrBuilder>(
                    metricsValues_,
                    ((bitField0_ & 0x00000002) == 0x00000002),
                    getParentForChildren(),
                    isClean());
            metricsValues_ = null;
          }
          return metricsValuesBuilder_;
        }

        // @@protoc_insertion_point(builder_scope:MetricsResponseProto.MetricsMapProto)
      }

      static {
        defaultInstance = new MetricsMapProto(true);
        defaultInstance.initFields();
      }

      // @@protoc_insertion_point(class_scope:MetricsResponseProto.MetricsMapProto)
    }

    // repeated .MetricsResponseProto.MetricsMapProto result = 1;
    public static final int RESULT_FIELD_NUMBER = 1;
    private java.util.List<com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto> result_;
    /**
     * <code>repeated .MetricsResponseProto.MetricsMapProto result = 1;</code>
     */
    public java.util.List<com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto> getResultList() {
      return result_;
    }
    /**
     * <code>repeated .MetricsResponseProto.MetricsMapProto result = 1;</code>
     */
    public java.util.List<? extends com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProtoOrBuilder> 
        getResultOrBuilderList() {
      return result_;
    }
    /**
     * <code>repeated .MetricsResponseProto.MetricsMapProto result = 1;</code>
     */
    public int getResultCount() {
      return result_.size();
    }
    /**
     * <code>repeated .MetricsResponseProto.MetricsMapProto result = 1;</code>
     */
    public com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto getResult(int index) {
      return result_.get(index);
    }
    /**
     * <code>repeated .MetricsResponseProto.MetricsMapProto result = 1;</code>
     */
    public com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProtoOrBuilder getResultOrBuilder(
        int index) {
      return result_.get(index);
    }

    private void initFields() {
      result_ = java.util.Collections.emptyList();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      for (int i = 0; i < getResultCount(); i++) {
        if (!getResult(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      for (int i = 0; i < result_.size(); i++) {
        output.writeMessage(1, result_.get(i));
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < result_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, result_.get(i));
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto)) {
        return super.equals(obj);
      }
      com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto other = (com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto) obj;

      boolean result = true;
      result = result && getResultList()
          .equals(other.getResultList());
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (getResultCount() > 0) {
        hash = (37 * hash) + RESULT_FIELD_NUMBER;
        hash = (53 * hash) + getResultList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code MetricsResponseProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return com.varone.hadoop.rpc.protos.MetricsProtos.internal_static_MetricsResponseProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return com.varone.hadoop.rpc.protos.MetricsProtos.internal_static_MetricsResponseProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.class, com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.Builder.class);
      }

      // Construct using com.haredb.sparkmonitor.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getResultFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (resultBuilder_ == null) {
          result_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          resultBuilder_.clear();
        }
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return com.varone.hadoop.rpc.protos.MetricsProtos.internal_static_MetricsResponseProto_descriptor;
      }

      public com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto getDefaultInstanceForType() {
        return com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.getDefaultInstance();
      }

      public com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto build() {
        com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto buildPartial() {
        com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto result = new com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto(this);
        int from_bitField0_ = bitField0_;
        if (resultBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            result_ = java.util.Collections.unmodifiableList(result_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.result_ = result_;
        } else {
          result.result_ = resultBuilder_.build();
        }
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto) {
          return mergeFrom((com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto other) {
        if (other == com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.getDefaultInstance()) return this;
        if (resultBuilder_ == null) {
          if (!other.result_.isEmpty()) {
            if (result_.isEmpty()) {
              result_ = other.result_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureResultIsMutable();
              result_.addAll(other.result_);
            }
            onChanged();
          }
        } else {
          if (!other.result_.isEmpty()) {
            if (resultBuilder_.isEmpty()) {
              resultBuilder_.dispose();
              resultBuilder_ = null;
              result_ = other.result_;
              bitField0_ = (bitField0_ & ~0x00000001);
              resultBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getResultFieldBuilder() : null;
            } else {
              resultBuilder_.addAllMessages(other.result_);
            }
          }
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        for (int i = 0; i < getResultCount(); i++) {
          if (!getResult(i).isInitialized()) {
            
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // repeated .MetricsResponseProto.MetricsMapProto result = 1;
      private java.util.List<com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto> result_ =
        java.util.Collections.emptyList();
      private void ensureResultIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          result_ = new java.util.ArrayList<com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto>(result_);
          bitField0_ |= 0x00000001;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto, com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.Builder, com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProtoOrBuilder> resultBuilder_;

      /**
       * <code>repeated .MetricsResponseProto.MetricsMapProto result = 1;</code>
       */
      public java.util.List<com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto> getResultList() {
        if (resultBuilder_ == null) {
          return java.util.Collections.unmodifiableList(result_);
        } else {
          return resultBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .MetricsResponseProto.MetricsMapProto result = 1;</code>
       */
      public int getResultCount() {
        if (resultBuilder_ == null) {
          return result_.size();
        } else {
          return resultBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .MetricsResponseProto.MetricsMapProto result = 1;</code>
       */
      public com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto getResult(int index) {
        if (resultBuilder_ == null) {
          return result_.get(index);
        } else {
          return resultBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .MetricsResponseProto.MetricsMapProto result = 1;</code>
       */
      public Builder setResult(
          int index, com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto value) {
        if (resultBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureResultIsMutable();
          result_.set(index, value);
          onChanged();
        } else {
          resultBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .MetricsResponseProto.MetricsMapProto result = 1;</code>
       */
      public Builder setResult(
          int index, com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.Builder builderForValue) {
        if (resultBuilder_ == null) {
          ensureResultIsMutable();
          result_.set(index, builderForValue.build());
          onChanged();
        } else {
          resultBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .MetricsResponseProto.MetricsMapProto result = 1;</code>
       */
      public Builder addResult(com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto value) {
        if (resultBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureResultIsMutable();
          result_.add(value);
          onChanged();
        } else {
          resultBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .MetricsResponseProto.MetricsMapProto result = 1;</code>
       */
      public Builder addResult(
          int index, com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto value) {
        if (resultBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureResultIsMutable();
          result_.add(index, value);
          onChanged();
        } else {
          resultBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .MetricsResponseProto.MetricsMapProto result = 1;</code>
       */
      public Builder addResult(
          com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.Builder builderForValue) {
        if (resultBuilder_ == null) {
          ensureResultIsMutable();
          result_.add(builderForValue.build());
          onChanged();
        } else {
          resultBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .MetricsResponseProto.MetricsMapProto result = 1;</code>
       */
      public Builder addResult(
          int index, com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.Builder builderForValue) {
        if (resultBuilder_ == null) {
          ensureResultIsMutable();
          result_.add(index, builderForValue.build());
          onChanged();
        } else {
          resultBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .MetricsResponseProto.MetricsMapProto result = 1;</code>
       */
      public Builder addAllResult(
          java.lang.Iterable<? extends com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto> values) {
        if (resultBuilder_ == null) {
          ensureResultIsMutable();
          super.addAll(values, result_);
          onChanged();
        } else {
          resultBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .MetricsResponseProto.MetricsMapProto result = 1;</code>
       */
      public Builder clearResult() {
        if (resultBuilder_ == null) {
          result_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          resultBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .MetricsResponseProto.MetricsMapProto result = 1;</code>
       */
      public Builder removeResult(int index) {
        if (resultBuilder_ == null) {
          ensureResultIsMutable();
          result_.remove(index);
          onChanged();
        } else {
          resultBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .MetricsResponseProto.MetricsMapProto result = 1;</code>
       */
      public com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.Builder getResultBuilder(
          int index) {
        return getResultFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .MetricsResponseProto.MetricsMapProto result = 1;</code>
       */
      public com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProtoOrBuilder getResultOrBuilder(
          int index) {
        if (resultBuilder_ == null) {
          return result_.get(index);  } else {
          return resultBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .MetricsResponseProto.MetricsMapProto result = 1;</code>
       */
      public java.util.List<? extends com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProtoOrBuilder> 
           getResultOrBuilderList() {
        if (resultBuilder_ != null) {
          return resultBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(result_);
        }
      }
      /**
       * <code>repeated .MetricsResponseProto.MetricsMapProto result = 1;</code>
       */
      public com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.Builder addResultBuilder() {
        return getResultFieldBuilder().addBuilder(
            com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.getDefaultInstance());
      }
      /**
       * <code>repeated .MetricsResponseProto.MetricsMapProto result = 1;</code>
       */
      public com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.Builder addResultBuilder(
          int index) {
        return getResultFieldBuilder().addBuilder(
            index, com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.getDefaultInstance());
      }
      /**
       * <code>repeated .MetricsResponseProto.MetricsMapProto result = 1;</code>
       */
      public java.util.List<com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.Builder> 
           getResultBuilderList() {
        return getResultFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto, com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.Builder, com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProtoOrBuilder> 
          getResultFieldBuilder() {
        if (resultBuilder_ == null) {
          resultBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto, com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProto.Builder, com.varone.hadoop.rpc.protos.MetricsProtos.MetricsResponseProto.MetricsMapProtoOrBuilder>(
                  result_,
                  ((bitField0_ & 0x00000001) == 0x00000001),
                  getParentForChildren(),
                  isClean());
          result_ = null;
        }
        return resultBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:MetricsResponseProto)
    }

    static {
      defaultInstance = new MetricsResponseProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:MetricsResponseProto)
  }

  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_MetricsRequestProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_MetricsRequestProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_MetricsResponseProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_MetricsResponseProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_MetricsResponseProto_MetricsMapProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_MetricsResponseProto_MetricsMapProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_MetricsResponseProto_MetricsMapProto_TupleProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_MetricsResponseProto_MetricsMapProto_TupleProto_fieldAccessorTable;

  public static com.google.protobuf.Descriptors.FileDescriptor
      getDescriptor() {
    return descriptor;
  }
  private static com.google.protobuf.Descriptors.FileDescriptor
      descriptor;
  static {
    java.lang.String[] descriptorData = {
      "\n\rmetrics.proto\"P\n\023MetricsRequestProto\022\025" +
      "\n\rapplicationId\030\001 \002(\t\022\"\n\007metrics\030\002 \003(\0162\021" +
      ".MetricsTypeProto\"\352\001\n\024MetricsResponsePro" +
      "to\0225\n\006result\030\001 \003(\0132%.MetricsResponseProt" +
      "o.MetricsMapProto\032\232\001\n\017MetricsMapProto\022\023\n" +
      "\013metricsName\030\001 \002(\t\022G\n\rmetricsValues\030\002 \003(" +
      "\01320.MetricsResponseProto.MetricsMapProto" +
      ".TupleProto\032)\n\nTupleProto\022\014\n\004time\030\001 \002(\003\022" +
      "\r\n\005value\030\002 \001(\t*\335\007\n\020MetricsTypeProto\022\006\n\002F" +
      "S\020\000\022\007\n\003JVM\020\001\022\006\n\002GC\020\002\022\017\n\013THREAD_POOL\020\003\022\037\n",
      "\033EXEC_FS_LOCAL_LARGEREAD_OPS\020\004\022\034\n\030EXEC_F" +
      "S_LOCAL_READ_BYTES\020\005\022\032\n\026EXEC_FS_LOCAL_RE" +
      "AD_OPS\020\006\022\035\n\031EXEC_FS_LOCAL_WRITE_BYTES\020\007\022" +
      "\033\n\027EXEC_FS_LOCAL_WRITE_OPS\020\010\022\036\n\032EXEC_FS_" +
      "HDFS_LARGEREAD_OPS\020\t\022\033\n\027EXEC_FS_HDFS_REA" +
      "D_BYTES\020\n\022\031\n\025EXEC_FS_HDFS_READ_OPS\020\013\022\034\n\030" +
      "EXEC_FS_HDFS_WRITE_BYTES\020\014\022\032\n\026EXEC_FS_HD" +
      "FS_WRITE_OPS\020\r\022\036\n\032EXEC_THREADPOOL_ACTIVE" +
      "TASK\020\016\022 \n\034EXEC_THREADPOOL_COMPLETETASK\020\017" +
      "\022!\n\035EXEC_THREADPOOL_CURRPOOL_SIZE\020\020\022 \n\034E",
      "XEC_THREADPOOL_MAXPOOL_SIZE\020\021\022\025\n\021JVM_HEA" +
      "P_COMMITED\020\022\022\021\n\rJVM_HEAP_INIT\020\023\022\020\n\014JVM_H" +
      "EAP_MAX\020\024\022\022\n\016JVM_HEAP_USAGE\020\025\022\021\n\rJVM_HEA" +
      "P_USED\020\026\022\031\n\025JVM_NON_HEAP_COMMITED\020\027\022\025\n\021J" +
      "VM_NON_HEAP_INIT\020\030\022\024\n\020JVM_NON_HEAP_MAX\020\031" +
      "\022\026\n\022JVM_NON_HEAP_USAGE\020\032\022\025\n\021JVM_NON_HEAP" +
      "_USED\020\033\022\036\n\032JVM_POOLS_CODE_CACHE_USAGE\020\034\022" +
      "!\n\035JVM_POOLS_PS_EDEN_SPACE_USAGE\020\035\022\036\n\032JV" +
      "M_POOLS_PS_OLD_GEN_USAGE\020\036\022\037\n\033JVM_POOLS_" +
      "PS_PERM_GEN_USAGE\020\037\022%\n!JVM_POOLS_PS_SURV",
      "IVOR_SPACE_USAGE\020 \022\032\n\026JVM_PS_MARKSWEEP_C" +
      "OUNT\020!\022\031\n\025JVM_PS_MARKSWEEP_TIME\020\"\022\031\n\025JVM" +
      "_PS_SCAVENGE_COUNT\020#\022\030\n\024JVM_PS_SCAVENGE_" +
      "TIME\020$B=\n)com.haredb.sparkmonitor.hadoop" +
      ".rpc.protosB\rMetricsProtos\240\001\001"
    };
    com.google.protobuf.Descriptors.FileDescriptor.InternalDescriptorAssigner assigner =
      new com.google.protobuf.Descriptors.FileDescriptor.InternalDescriptorAssigner() {
        public com.google.protobuf.ExtensionRegistry assignDescriptors(
            com.google.protobuf.Descriptors.FileDescriptor root) {
          descriptor = root;
          internal_static_MetricsRequestProto_descriptor =
            getDescriptor().getMessageTypes().get(0);
          internal_static_MetricsRequestProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_MetricsRequestProto_descriptor,
              new java.lang.String[] { "ApplicationId", "Metrics", });
          internal_static_MetricsResponseProto_descriptor =
            getDescriptor().getMessageTypes().get(1);
          internal_static_MetricsResponseProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_MetricsResponseProto_descriptor,
              new java.lang.String[] { "Result", });
          internal_static_MetricsResponseProto_MetricsMapProto_descriptor =
            internal_static_MetricsResponseProto_descriptor.getNestedTypes().get(0);
          internal_static_MetricsResponseProto_MetricsMapProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_MetricsResponseProto_MetricsMapProto_descriptor,
              new java.lang.String[] { "MetricsName", "MetricsValues", });
          internal_static_MetricsResponseProto_MetricsMapProto_TupleProto_descriptor =
            internal_static_MetricsResponseProto_MetricsMapProto_descriptor.getNestedTypes().get(0);
          internal_static_MetricsResponseProto_MetricsMapProto_TupleProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_MetricsResponseProto_MetricsMapProto_TupleProto_descriptor,
              new java.lang.String[] { "Time", "Value", });
          return null;
        }
      };
    com.google.protobuf.Descriptors.FileDescriptor
      .internalBuildGeneratedFileFrom(descriptorData,
        new com.google.protobuf.Descriptors.FileDescriptor[] {
        }, assigner);
  }

  // @@protoc_insertion_point(outer_class_scope)
}
